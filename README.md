# Awesome-LLM-RL [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

Inspired by the [awesome-embodied-vision](https://github.com/rxlqn/awesome-embodied-vision)

## <a name="papers"></a> Papers

- Ahmadian, A., Cremer, C., Gallé, M., Fadaee, M., Kreutzer, J., Pietquin, O., Üstün, A., & Hooker, S. (2024). _Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs_ (No. arXiv:2402.14740). arXiv. [https://doi.org/10.48550/arXiv.2402.14740](https://doi.org/10.48550/arXiv.2402.14740)

- Havrilla, A., Du, Y., Raparthy, S. C., Nalmpantis, C., Dwivedi-Yu, J., Hambro, E., Sukhbaatar, S., & Raileanu, R. (2024, June 13). _Teaching Large Language Models to Reason with Reinforcement Learning_. AI for Math Workshop @ ICML 2024. [https://openreview.net/forum?id=mjqoceuMnI](https://openreview.net/forum?id=mjqoceuMnI)

- Hu, J., Wu, X., Zhu, Z., Xianyu, Wang, W., Zhang, D., & Cao, Y. (2024). _OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework_ (No. arXiv:2405.11143). arXiv. [https://doi.org/10.48550/arXiv.2405.11143](https://doi.org/10.48550/arXiv.2405.11143)

- Kumar, A., Zhuang, V., Agarwal, R., Su, Y., Co-Reyes, J. D., Singh, A., Baumli, K., Iqbal, S., Bishop, C., Roelofs, R., Zhang, L. M., McKinney, K., Shrivastava, D., Paduraru, C., Tucker, G., Precup, D., Behbahani, F., & Faust, A. (2024). _Training Language Models to Self-Correct via Reinforcement Learning_ (No. arXiv:2409.12917). arXiv. [https://doi.org/10.48550/arXiv.2409.12917](https://doi.org/10.48550/arXiv.2409.12917)

- Lightman, H., Kosaraju, V., Burda, Y., Edwards, H., Baker, B., Lee, T., Leike, J., Schulman, J., Sutskever, I., & Cobbe, K. (2023, October 13). _Let’s Verify Step by Step_. The Twelfth International Conference on Learning Representations. [https://openreview.net/forum?id=v8L0pN6EOi](https://openreview.net/forum?id=v8L0pN6EOi)

- Shao, Z., Wang, P., Zhu, Q., Xu, R., Song, J., Bi, X., Zhang, H., Zhang, M., Li, Y. K., Wu, Y., & Guo, D. (2024). _DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models_ (No. arXiv:2402.03300). arXiv. [https://doi.org/10.48550/arXiv.2402.03300](https://doi.org/10.48550/arXiv.2402.03300)

- Snell, C., Lee, J., Xu, K., & Kumar, A. (2024). _Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters_ (No. arXiv:2408.03314). arXiv. [http://arxiv.org/abs/2408.03314](http://arxiv.org/abs/2408.03314)

- Xi, Z., Yang, D., Huang, J., Tang, J., Li, G., Ding, Y., He, W., Hong, B., Do, S., Zhan, W., Wang, X., Zheng, R., Ji, T., Shi, X., Zhai, Y., Weng, R., Wang, J., Cai, X., Gui, T., … Jiang, Y.-G. (2024). _Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision_ (No. arXiv:2411.16579). arXiv. [https://doi.org/10.48550/arXiv.2411.16579](https://doi.org/10.48550/arXiv.2411.16579)

- Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., & Narasimhan, K. (2023). _Tree of Thoughts: Deliberate Problem Solving with Large Language Models_ (No. arXiv:2305.10601). arXiv. [https://doi.org/10.48550/arXiv.2305.10601](https://doi.org/10.48550/arXiv.2305.10601)

- Zelikman, E., Wu, Y., Mu, J., & Goodman, N. D. (2022). _STaR: Bootstrapping Reasoning With Reasoning_ (No. arXiv:2203.14465). arXiv. [https://doi.org/10.48550/arXiv.2203.14465](https://doi.org/10.48550/arXiv.2203.14465)

- Zeng, Z., Cheng, Q., Yin, Z., Wang, B., Li, S., Zhou, Y., Guo, Q., Huang, X., & Qiu, X. (2024). _Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective_ (No. arXiv:2412.14135). arXiv. [https://doi.org/10.48550/arXiv.2412.14135](https://doi.org/10.48550/arXiv.2412.14135)
